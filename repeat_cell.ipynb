{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import CompDoobTransform as cdt\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from CompDoobTransform.utils import normal_logpdf\n",
    "plt.style.use('ggplot')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Computing on ' + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning parameters \n",
    "std_obs = 0.25\n",
    "filename = 'cell_var_obs_small.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict for objects relating to latent state process\n",
    "state = {}\n",
    "\n",
    "# dimension of state \n",
    "d = 2 \n",
    "state['dim'] = d\n",
    "\n",
    "# drift of diffusion\n",
    "alpha = torch.tensor(1.0)\n",
    "beta = torch.tensor(1.0)\n",
    "kappa = torch.tensor(1.0)\n",
    "P = torch.tensor(4.0)\n",
    "xi = torch.tensor(0.5)\n",
    "\n",
    "# drift\n",
    "def drift(x):\n",
    "    out = torch.zeros(x.shape)    \n",
    "    out[:,0] = alpha * x[:,0]**P / (xi**P + x[:,0]**P) + beta * xi**P / (xi**P + x[:,1]**P) - kappa * x[:,0]\n",
    "    out[:,1] = alpha * x[:,1]**P / (xi**P + x[:,1]**P) + beta * xi**P / (xi**P + x[:,0]**P) - kappa * x[:,1]\n",
    "    return out\n",
    "b = lambda x: drift(x)\n",
    "state['drift'] = b\n",
    "\n",
    "# diffusion coefficient of diffusion\n",
    "sigma = torch.tensor(1.0, device = device) # diffusion coefficient\n",
    "state['sigma'] = sigma\n",
    "\n",
    "# time interval\n",
    "T = torch.tensor(1.0, device = device) \n",
    "state['terminal_time'] = T\n",
    "\n",
    "# time-discretization settings\n",
    "M = 50 # number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict for objects relating to observations\n",
    "obs = {}\n",
    "\n",
    "# dimension of observation\n",
    "p = 2\n",
    "obs['dim'] = p\n",
    "\n",
    "# observation parameters\n",
    "var_obs = torch.tensor(std_obs**2, device = device) # variance of observation\n",
    "\n",
    "# log-observation density\n",
    "obs_log_density = lambda x, y: normal_logpdf(y, x, var_obs) # terminal condition, returns size (N)\n",
    "obs['log_density'] = obs_log_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate states and observations from model\n",
    "X0 = torch.ones(1,d)\n",
    "X = X0.clone()\n",
    "J = 2000\n",
    "max_index = J*M+1\n",
    "store_states = torch.zeros(J*M+1, d, device = device)\n",
    "store_states[0,:] = X    \n",
    "store_obs = torch.zeros(J*M, d, device = device)\n",
    "stepsize = torch.tensor(T / M, device = device)\n",
    "for j in range(J):\n",
    "    for m in range(M):\n",
    "        euler = X + stepsize * b(X)\n",
    "        W = torch.sqrt(stepsize) * torch.randn(X.shape, device = device)\n",
    "        X = euler + sigma * W\n",
    "        Y = X + torch.sqrt(var_obs) * torch.randn(1, p, device = device)\n",
    "        index = j*M + m + 1\n",
    "        store_states[index,:] = X\n",
    "        store_obs[index-1,:] = Y\n",
    "\n",
    "# learning standardization means and standard deviations\n",
    "standardization = {'x_mean': torch.mean(store_states, 0), \n",
    "                   'x_std': torch.std(store_states, 0), \n",
    "                   'y_mean': torch.mean(store_obs, 0), \n",
    "                   'y_std': torch.std(store_obs, 0)}\n",
    "print(standardization)\n",
    "\n",
    "# simulate initial states\n",
    "initial = lambda N: store_states[torch.randint(0, max_index, size = (N,)), :] # function to subsample states\n",
    "state['initial'] = initial\n",
    "\n",
    "# simulate observations\n",
    "observation = lambda N: initial(N) + torch.sqrt(var_obs) * torch.randn(N, p, device = device)\n",
    "obs['observation'] = observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V0 and Z neural network configuration\n",
    "V0_net_config = {'layers': [16], 'standardization': standardization}\n",
    "Z_net_config = {'layers': [d+16], 'standardization': standardization}\n",
    "net_config = {'V0': V0_net_config, 'Z': Z_net_config}\n",
    "\n",
    "# learning type\n",
    "# learning_type = 'standard'\n",
    "learning_type = 'iterative'                \n",
    "\n",
    "# create model instance\n",
    "model = cdt.core.model(state, obs, M, net_config, device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization configuration (standard training)\n",
    "I = 2000\n",
    "optim_config = {'minibatch': 100, \n",
    "                'num_obs_per_batch': 10, \n",
    "                'num_iterations': I,\n",
    "                'learning_rate' : 0.01, \n",
    "                'initial_required' : True}\n",
    "# training\n",
    "time_start = time.time() \n",
    "if learning_type == 'standard':\n",
    "    model.train_standard(optim_config)\n",
    "if learning_type == 'iterative':\n",
    "    model.train_iterative(optim_config)\n",
    "time_end = time.time()\n",
    "time_elapsed = time_end - time_start\n",
    "print(\"Training time (secs): \" + str(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss over optimization iterations\n",
    "plt.figure()\n",
    "plt.plot(torch.arange(I), model.loss.to('cpu'), 'k.')\n",
    "plt.xlabel('iteration', fontsize = 15)\n",
    "plt.ylabel('loss', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat particle filters\n",
    "multiplier = 1.0\n",
    "num_obs = [100, 200, 400, 800, 1600]\n",
    "len_num_obs = len(num_obs)\n",
    "num_particles = [2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "R = 100 # number of repeats\n",
    "BPF = {'ess' : torch.zeros(len_num_obs, R), 'log_estimate' : torch.zeros(len_num_obs, R)}\n",
    "APF = {'ess' : torch.zeros(len_num_obs, R), 'log_estimate' : torch.zeros(len_num_obs, R)}\n",
    "\n",
    "for i in range(len_num_obs):\n",
    "    # number of observations\n",
    "    K = num_obs[i]\n",
    "\n",
    "    # number of particles\n",
    "    N = num_particles[i]\n",
    "\n",
    "    # simulate latent process and observations\n",
    "    X0 = torch.ones(1,d)\n",
    "    X = torch.zeros(K+1, d)\n",
    "    X[0,:] = X0.clone()\n",
    "    Y = torch.zeros(K, p)\n",
    "    for k in range(K):\n",
    "        X[k+1,:] = model.simulate_diffusion(X[k,:].reshape((1,d)))\n",
    "        Y[k,:] = X[k+1,:] + multiplier * torch.sqrt(var_obs) * torch.randn(1,p)\n",
    "\n",
    "    for r in range(R):\n",
    "        # run particle filters\n",
    "        BPF_output = model.run_BPF(X0.repeat((N,1)), Y, N)\n",
    "        APF_output = model.run_APF(X0.repeat((N,1)), Y, N)\n",
    "\n",
    "        # save average ESS%\n",
    "        BPF_ESS = torch.mean(BPF_output['ess'] * 100 / N)\n",
    "        APF_ESS = torch.mean(APF_output['ess'] * 100 / N)\n",
    "        BPF['ess'][i,r] = BPF_ESS\n",
    "        APF['ess'][i,r] = APF_ESS\n",
    "\n",
    "        # save log-likelihood estimates\n",
    "        BPF_log_estimate = BPF_output['log_norm_const'][-1]\n",
    "        APF_log_estimate = APF_output['log_norm_const'][-1]\n",
    "        BPF['log_estimate'][i,r] = BPF_log_estimate\n",
    "        APF['log_estimate'][i,r] = APF_log_estimate\n",
    "\n",
    "        # print output\n",
    "        print('No. of observations: ' + str(K) + ' Repeat: ' + str(r)) \n",
    "        print('BPF ESS%: ' + str(BPF_ESS))\n",
    "        print('APF ESS%: ' + str(APF_ESS)) \n",
    "        print('BPF log-estimate: ' + str(BPF_log_estimate))\n",
    "        print('APF log-estimate: ' + str(APF_log_estimate))\n",
    "\n",
    "# save results\n",
    "results = {'BPF' : BPF, 'APF' : APF}\n",
    "torch.save(results, filename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88f8cf8e21ecdddc206b113d2af7f84f81c01e5536c8050713d03d2f94453c4b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('standard')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
